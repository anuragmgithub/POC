# Anatomy of a Flink Cluster  
The Flink runtime consists of two types of processes
- a JobManager 
- one or more TaskManagers

![alt text](image.png)

## JobManager:  
The JobManager has a number of responsibilities related to coordinating the distributed execution of Flink Applications:  
- it decides when to schedule the next task (or set of tasks)  
- reacts to finished tasks or execution failures  
- coordinates checkpoints  
- and coordinates recovery on failures  

This process consists of three different components:  
- ResourceManager  
- Dispatcher  
- JobMaster  

## TaskManagers:  
- The TaskManagers (also called workers) execute the tasks of a dataflow, and buffer and exchange the data streams.  
- The smallest unit of resource scheduling in a TaskManager is a task slot. The number of task slots in a TaskManager indicates the number of concurrent processing tasks.  

ðŸ”¹ Flink's distributed execution model consists of:  

JobManager â€“ Manages task scheduling and failure recovery.  
TaskManager â€“ Executes tasks and maintains state.  
Checkpointing & State Backend â€“ Ensures fault tolerance.  

ðŸ“Œ Key Concepts:
âœ… Stream Processing vs Batch Processing â€“ Flink supports both.
âœ… Event Time, Processing Time, and Ingestion Time â€“ Important for accurate event handling.

ðŸ“Œ Key APIs to Learn:    
âœ… DataStream API â€“ Handles unbounded data streams.  
âœ… DataSet API â€“ Used for batch processing.  
âœ… Table API & SQL â€“ Used for declarative queries.     

---

### Checkpointing & State Management (Fault Tolerance): 
ðŸ“Œ Enable Checkpointing:  
env.enableCheckpointing(5000);  // Checkpoint every 5 seconds

ðŸ“Œ State Backends:  
âœ… MemoryStateBackend â€“ Fast but limited to small jobs.  
âœ… FsStateBackend â€“ Saves state to disk/HDFS.  
âœ… RocksDBStateBackend â€“ Recommended for large-scale production workloads.  

ðŸ“Œ Configuring RocksDB State Backend (Recommended for production):  

#### Windowing & Watermarks (Handling Event Time):  
ðŸ“Œ Key Concepts:  
âœ… Tumbling Window â€“ Fixed-size, non-overlapping windows.  
âœ… Sliding Window â€“ Overlapping windows with a fixed step size.  
âœ… Session Window â€“ Dynamic based on activity gaps.  
âœ… Watermarks help handle out-of-order events.  
âœ… Event Time vs Processing Time  

--
## Handling High Throughput & Performance Tuning:  
ðŸ“Œ Optimize Parallelism:  
```
env.setParallelism(4);
```
ðŸ“Œ Enable Asynchronous Checkpoints:
```
env.getCheckpointConfig().enableUnalignedCheckpoints();
```
ðŸ“Œ Configure RocksDB for Large-Scale Jobs:  
```
env.setStateBackend(new RocksDBStateBackend("hdfs:///flink-checkpoints"));
```

## What is an Operator in Flink?  
In Apache Flink, an operator is a fundamental building block of a data processing pipeline. Operators define how data is transformed,   processed, or aggregated as it flows through the Flink job.  

Types of Operators in Flink:  
- Source Operators (Reading Data):  
- Transformation Operators (Processing Data)  
Common transformations include map, filter, flatMap, keyBy, window, reduce, and join.   
- Sink Operators (Writing Data):  

 Operator Chaining in Flink:  
 Flink automatically chains compatible operators together into a single task to improve performance.  

 ### Tasks and Operator Chains in Flink:  
 In Apache Flink, a task is the unit of execution, and operator chaining is an optimization that combines multiple operators into a single task to improve efficiency.

Consider the following data pipeline:  
Source â†’ Map â†’ Filter â†’ KeyBy â†’ Window Aggregate â†’ Sink   
Task #	Chained Operators  
Task 1	Source  
Task 2	Map â†’ Filter  
Task 3	KeyBy  
Task 4	Window Aggregate  
Task 5	Sink  
Here, Map and Filter are chained together into a single task, reducing unnecessary overhead. 

### Why does Flink have separate concepts of Distributed State and Checkpointing?  
What is Distributed State?  

Distributed State is the live, in-memory state that Flink operators maintain while processing streaming data.  

In a Flink job, the state is attached to operators and distributed across TaskManagers.  

Types of Distributed State:  
Type	                  Description
Keyed State	              Maintained per key; distributed across partitions
Operator State	          Local to operator instance (example: Kafka consumer offsets)

Why Distributed State Exists:  
- Enables stateful stream processing (aggregations, pattern matching, ML features, etc.)  
- Scales horizontally as state is split across cluster nodes. 
- Provides high throughput & low latency since it lives in fast local memory or RocksDB  

What is Checkpointing?  
Checkpointing creates periodic, consistent snapshots of distributed state and stores them in durable storage (e.g., S3, HDFS).  

Why Checkpointing Exists?  
- Provides fault tolerance for streaming applications
- Allows job recovery without data or state loss
- Enables exactly-once processing guarantees  


### Flink vs spark checkpointing:  

![alt text](image-1.png)


### Spark vs flink timeline:  
Time â†’ 

Spark Structured Streaming (Batch Interval = 5 sec)
|--------- Batch 1 ---------|--------- Batch 2 ---------|
Events arrive â†’ Buffered â†’ Process batch â†’ Commit outputs
Processing latency â‰ˆ 5 sec
Output visible after batch
Real-time actions â†’ delayed by batch (cannot trigger instantly)

Flink Streaming (Checkpoint Interval = 5 sec)
Event1 Event2 Event3 Event4 ...
  |     |     |     |
Process instantly â†’ trigger real-time actions (alerts, API calls)
Sink write buffered â†’ committed at checkpoint boundary
Processing latency = ms
Output visibility latency â‰ˆ checkpoint interval (5 sec)   

### Apache Flink Real-Time Processing & Exactly-Once Semantics  
1. Checkpointing and State Management  
- Flink maintains distributed state and periodically takes checkpoints for recovery.  
- Checkpoints store source offsets, operator state, timers, and watermark positions.  
- On failure, Flink restores state from the latest checkpoint, ensuring no data loss.  

--- 

2. Exactly-Once Semantics  
- Exactly-once guarantees that state updates and transactional sinks are committed once, even after failures.  
- Checkpoint interval determines when transactional sinks are committed, e.g., every 5 seconds.  
- Processing is continuous, but output visibility for sinks happens at checkpoint boundaries.  
- External side effects (e.g., alerts, API calls) are not automatically exactly-once; they require idempotency to avoid duplicates.  

---   

3. At-Least-Once Semantics  
- Records are written immediately to sinks, but duplicates may occur on failure/replay.  
- Checkpoints are still used for state recovery.  
- Latency is lower than exactly-once, but consumers must handle duplicates via idempotent writes or deduplication.  







  