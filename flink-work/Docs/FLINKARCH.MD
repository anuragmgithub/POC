# Anatomy of a Flink Cluster  
The Flink runtime consists of two types of processes
- a JobManager 
- one or more TaskManagers

![alt text](image.png)

## JobManager:  
The JobManager has a number of responsibilities related to coordinating the distributed execution of Flink Applications:  
- it decides when to schedule the next task (or set of tasks)  
- reacts to finished tasks or execution failures  
- coordinates checkpoints  
- and coordinates recovery on failures  

This process consists of three different components:  
- ResourceManager  
- Dispatcher  
- JobMaster  

## TaskManagers:  
- The TaskManagers (also called workers) execute the tasks of a dataflow, and buffer and exchange the data streams.  
- The smallest unit of resource scheduling in a TaskManager is a task slot. The number of task slots in a TaskManager indicates the number of concurrent processing tasks.  

ðŸ”¹ Flink's distributed execution model consists of:  

JobManager â€“ Manages task scheduling and failure recovery.  
TaskManager â€“ Executes tasks and maintains state.  
Checkpointing & State Backend â€“ Ensures fault tolerance.  

ðŸ“Œ Key Concepts:
âœ… Stream Processing vs Batch Processing â€“ Flink supports both.
âœ… Event Time, Processing Time, and Ingestion Time â€“ Important for accurate event handling.

ðŸ“Œ Key APIs to Learn:    
âœ… DataStream API â€“ Handles unbounded data streams.  
âœ… DataSet API â€“ Used for batch processing.  
âœ… Table API & SQL â€“ Used for declarative queries.     

---

### Checkpointing & State Management (Fault Tolerance): 
ðŸ“Œ Enable Checkpointing:  
env.enableCheckpointing(5000);  // Checkpoint every 5 seconds

ðŸ“Œ State Backends:  
âœ… MemoryStateBackend â€“ Fast but limited to small jobs.  
âœ… FsStateBackend â€“ Saves state to disk/HDFS.  
âœ… RocksDBStateBackend â€“ Recommended for large-scale production workloads.  

ðŸ“Œ Configuring RocksDB State Backend (Recommended for production):  

#### Windowing & Watermarks (Handling Event Time):  
ðŸ“Œ Key Concepts:  
âœ… Tumbling Window â€“ Fixed-size, non-overlapping windows.  
âœ… Sliding Window â€“ Overlapping windows with a fixed step size.  
âœ… Session Window â€“ Dynamic based on activity gaps.  
âœ… Watermarks help handle out-of-order events.  
âœ… Event Time vs Processing Time  

--
## Handling High Throughput & Performance Tuning:  
ðŸ“Œ Optimize Parallelism:  
```
env.setParallelism(4);
```
ðŸ“Œ Enable Asynchronous Checkpoints:
```
env.getCheckpointConfig().enableUnalignedCheckpoints();
```
ðŸ“Œ Configure RocksDB for Large-Scale Jobs:  
```
env.setStateBackend(new RocksDBStateBackend("hdfs:///flink-checkpoints"));
```

## What is an Operator in Flink?  
In Apache Flink, an operator is a fundamental building block of a data processing pipeline. Operators define how data is transformed,   processed, or aggregated as it flows through the Flink job.  

Types of Operators in Flink:  
- Source Operators (Reading Data):  
- Transformation Operators (Processing Data)  
Common transformations include map, filter, flatMap, keyBy, window, reduce, and join.   
- Sink Operators (Writing Data):  

 Operator Chaining in Flink:  
 Flink automatically chains compatible operators together into a single task to improve performance.  

 ### Tasks and Operator Chains in Flink:  
 In Apache Flink, a task is the unit of execution, and operator chaining is an optimization that combines multiple operators into a single task to improve efficiency.

Consider the following data pipeline:  
Source â†’ Map â†’ Filter â†’ KeyBy â†’ Window Aggregate â†’ Sink   
Task #	Chained Operators  
Task 1	Source  
Task 2	Map â†’ Filter  
Task 3	KeyBy  
Task 4	Window Aggregate  
Task 5	Sink  
Here, Map and Filter are chained together into a single task, reducing unnecessary overhead.  



